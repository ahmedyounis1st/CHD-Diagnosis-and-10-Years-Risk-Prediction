# -*- coding: utf-8 -*-
"""final_project_chd_diagnostic_traditional_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ekqfLJGqEtV0PYaOP4NRpPTr6jNrHjpN
"""

#import Libraries 
from tensorflow import keras
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler , StandardScaler
from sklearn.model_selection import train_test_split 
import matplotlib.pyplot as plt
import seaborn as sns

#import data
chd_data=pd.read_csv('/content/CHDdata diagnosis.csv')
chd_data

#check for null value 
chd_data.isnull().sum()

#check for duplicated
chd_data.duplicated().sum()

#check data types
chd_data.dtypes

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
le.fit(chd_data.iloc[:,4])
chd_data.iloc[:,4]=le.transform(chd_data.iloc[:,4])
chd_data

Index = np.r_[0:4,5:9]
plt.figure(figsize=(16,5))
chd_data.iloc[:,Index].boxplot()
plt.title("Distribution of the values ​​of all potential predictors")
plt.show()

outliers = ['sbp', 'tobacco', 'ldl', 'typea', 'obesity', 'alcohol']
for column in outliers:
  Q1,Q3 = np.percentile(chd_data[column],[25,75])
  IQR = Q3 - Q1
  lower_fence = Q1 - (1.5*IQR)
  upper_fence = Q3 + (1.5*IQR)  
  chd_data[column] = chd_data[column].apply(lambda x: upper_fence if x>upper_fence
                                              else lower_fence if x<lower_fence else x)

plt.figure(figsize=(16,5))
sns.boxplot(data=chd_data.iloc[:,Index])
plt.title("Distribution of the values ​​of all potential predictors")
plt.grid()
plt.show()

chd_data.to_csv('diagnosis_clean.csv', index=False)

df_clean = pd.read_csv('diagnosis_clean.csv')
df_clean.head()

#rescaling
scaler = StandardScaler()
chd_data.iloc[:,Index] = scaler.fit_transform(chd_data.iloc[:,Index])
chd_data.iloc[0:5,:]

plt.figure(figsize=(16,5))
sns.boxplot(data=chd_data.iloc[:,Index])
plt.title("Distribution of the values ​​of all potential standardized predictors")
plt.grid()
plt.show()

#spliting data
x=chd_data.iloc[:,:-1]
y=chd_data.iloc[:,-1]
x

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=23)

x_train.iloc[0,:]

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, recall_score

classifiers = []
classifiers.append(("LR",LogisticRegression(random_state=0)))
classifiers.append(("NB",GaussianNB()))
classifiers.append(("DT",DecisionTreeClassifier(random_state = 0)))
classifiers.append(("RF",RandomForestClassifier(random_state = 0)))
classifiers.append(("SVM",SVC()))
classifiers.append(("KNN", KNeighborsClassifier()))
scores = []
clf_names = []

my_list = [ 0.2, 0.25, 0.33, 0.4]
for clf in classifiers:
  score = 0
  recall = 0
  for p in my_list:
    for i in range(101):
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = p, random_state = i)
      classifier = clf[1]
      classifier.fit(X_train,y_train)
      y_pred = classifier.predict(X_test)
      acc_score = (accuracy_score(y_test,y_pred)*100).round(2)
      rec_score = recall_score(y_test,y_pred)
      if acc_score > score:
          score = acc_score
          recall = rec_score
          paramters = (p, i, score, recall)
  p, i, score, recall = paramters
  print("classifier = {}, P = {}, i = {}, score = {}, recall = {}".format(classifier, p,i,score, recall))

my_list = [ 0.2, 0.25, 0.33, 0.4]
for clf in classifiers:
  score = 0
  recall = 0
  for p in my_list:
    for i in range(101):
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = p, random_state = i)
      classifier = clf[1]
      classifier.fit(X_train,y_train)
      y_pred = classifier.predict(X_test)
      acc_score = (accuracy_score(y_test,y_pred)*100).round(2)
      rec_score = recall_score(y_test,y_pred)
      if rec_score > recall:
          score = acc_score
          recall = rec_score
          paramters = (p, i, score, recall)
  p, i, score, recall = paramters
  print("classifier = {}, P = {}, i = {}, score = {}, recall = {}".format(classifier, p,i,score, recall))

# Applying GridSearch on the dataset to Check the best paramters for our Classification
from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV
for classifier_name, classifier in classifiers:
    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=0)
    if classifier_name == "LR" : 
        parameters = [{'solver' : ['newton-cg', 'lbfgs'], 'penalty' : ['l2'], 
                       'C':[100, 10, 1, 0.1, 0.01],'multi_class':['auto', 'ovr', 'multinomial']},
                      {'solver': ['liblinear'],'penalty' : ['l1', 'l2'],
                       'C':[100, 10, 1, 0.1, 0.01],'multi_class':['auto', 'ovr'],'random_state':[0,1,42]}]
    elif classifier_name == "NB" : 
        continue           
    elif classifier_name == "DT" :
        parameters = [{'criterion' : ['gini', 'entropy'],'random_state':[ 0, 1, 12, 42],
                        'splitter':['best', 'random'], 'max_features': ['sqrt', 'log2']}]
    elif classifier_name == "RF" :
        parameters = [{'bootstrap':[True], 'criterion' : ['gini', 'entropy'], 'n_estimators':[10,15,20,25],
                        'max_depth':[110,130,150,170], 'random_state':[ 0, 1 , 42],
                       'min_samples_leaf':[7,9,11,13],'min_samples_split':[8,12,14],'max_features': ['sqrt', 'log2']}]
    elif classifier_name == "SVM" :
        parameters = [{'C':[100, 10, 1, 0.1, 0.01], 'gamma' : ['auto', 'scale'],
                       'kernel': ['poly', 'rbf', 'sigmoid']},
                      {'C':[100, 10, 1, 0.1, 0.01], 'kernel': ['linear']}]    
    elif classifier_name == "KNN" :
        parameters = [{'n_neighbors': range(1, 21, 2),
                       'weights' : ['uniform', 'distance'],'n_jobs': [-1],
                       'algorithm' : ['auto', 'ball_tree', 'kd_tree','brute']}]
    grid_search= GridSearchCV(estimator = classifier,
                              param_grid = parameters,
                              scoring = 'accuracy',
                              cv = cv, n_jobs = -1)
    grid_search = grid_search.fit(x, y)
    best_accuracy = grid_search.best_score_
    best_parameters = grid_search.best_params_
    print(classifier_name," (best score) : ", best_accuracy)
    print("best parameters : ", best_parameters)

classifiers = []
classifiers.append(("LR",LogisticRegression(C = 0.1, multi_class =  'auto', penalty = 'l2', solver =  'newton-cg')))
classifiers.append(("NB",GaussianNB()))
classifiers.append(("DT",DecisionTreeClassifier(criterion = 'entropy', max_features ='sqrt', random_state = 1, splitter = 'best')))
classifiers.append(("RF",RandomForestClassifier(bootstrap = True, criterion = 'entropy', max_depth = 110, max_features = 'sqrt', 
                                                min_samples_leaf = 11, min_samples_split = 8, n_estimators = 25, random_state = 42)))
classifiers.append(("SVM",SVC(C = 1, gamma = 'auto', kernel = 'rbf')))
classifiers.append(("KNN", KNeighborsClassifier(algorithm = 'auto', n_jobs = -1, n_neighbors = 13, weights = 'distance')))

my_list = [ 0.2, 0.25, 0.33, 0.4]
for clf in classifiers:
  score = 0
  recall = 0
  for p in my_list:
    for i in range(101):
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = p, random_state = i)
      classifier = clf[1]
      classifier.fit(X_train,y_train)
      y_pred = classifier.predict(X_test)
      acc_score = (accuracy_score(y_test,y_pred)*100).round(2)
      rec_score = recall_score(y_test,y_pred)
      if acc_score > score:
          score = acc_score
          recall = rec_score
          paramters = (p, i, score, recall)
  p, i, score, recall = paramters
  print("classifier = {}, P = {}, i = {}, score = {}, recall = {}".format(classifier, p, i, score, recall))

my_list = [ 0.2, 0.25, 0.33, 0.4]
for clf in classifiers:
  score = 0
  recall = 0
  for p in my_list:
    for i in range(101):
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = p, random_state = i)
      classifier = clf[1]
      classifier.fit(X_train,y_train)
      y_pred = classifier.predict(X_test)
      acc_score = (accuracy_score(y_test,y_pred)*100).round(2)
      rec_score = recall_score(y_test,y_pred)
      if rec_score > recall:
          score = acc_score
          recall = rec_score
          paramters = (p, i, score, recall)
  p, i, score, recall = paramters
  print("classifier = {}, P = {}, i = {}, score = {}, recall = {}".format(classifier, p,i,score, recall))

"""## Final Model

### Highest Accuarcy Model

### Logistic Regression Classifier
"""

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 67)
X_train.iloc[0,:]

lr_acc_clf = LogisticRegression(C = 0.1, multi_class =  'auto', penalty = 'l2', solver =  'newton-cg')
lr_acc_clf.fit(X_train,y_train)

lr_train_score = lr_acc_clf.score(X_train,y_train)
lr_test_score = lr_acc_clf.score(X_test,y_test)
print('Model Train Score: {} '.format(lr_train_score))
print('Model Test Score: {} '.format(lr_test_score))

y_pred_lr = lr_acc_clf.predict(X_test)
lr_acc_score = (accuracy_score(y_test,y_pred_lr)*100).round(2)
print("Logistic Regression Highest Accuarcy: {} % ".format(lr_acc_score))

"""### KNN Classifier"""

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 62)
X_train.iloc[0,:]

knn_acc_clf = KNeighborsClassifier(algorithm = 'auto', n_jobs = -1, n_neighbors = 13, weights = 'distance')
knn_acc_clf.fit(X_train,y_train)

knn_train_score = knn_acc_clf.score(X_train,y_train)
knn_test_score = knn_acc_clf.score(X_test,y_test)
print('Model Train Score: {}'.format(knn_train_score))
print('Model Test Score: {}'.format(knn_test_score))

y_pred_knn = knn_acc_clf.predict(X_test)
knn_acc_score = (accuracy_score(y_test,y_pred_knn)*100).round(2)
print("KNN Highest Accuarcy: {} % ".format(knn_acc_score))

"""### Support Vector Machine"""

svc_acc_clf = SVC(C = 1, gamma = 'auto', kernel = 'rbf')
svc_acc_clf.fit(X_train,y_train)

svc_train_score = svc_acc_clf.score(X_train,y_train)
svc_test_score = svc_acc_clf.score(X_test,y_test)
print('Model Train Score: {}'.format(svc_train_score))
print('Model Test Score: {}'.format(svc_test_score))

y_pred_svc = svc_acc_clf.predict(X_test)
svc_acc_score = (accuracy_score(y_test,y_pred_svc)*100).round(2)
print("SVC Highest Accuarcy: {} % ".format(svc_acc_score))

"""### Highest Recall Model"""

rec_clf = GaussianNB()
rec_clf.fit(X_train,y_train)

y_pred_rec = rec_clf.predict(X_test)
rec_score = (recall_score(y_test,y_pred_rec)*100).round(2)
print("Highest Recall: {} % ".format(rec_score))

"""## Save Optmial Model"""

import pickle

filename = 'chd_diagnostic_best_recall_model.sav'
pickle.dump(rec_clf, open(filename, 'wb'))

filename = 'chd_diagnostic_best_accuarcy_model.sav'
pickle.dump(svc_acc_clf, open(filename, 'wb'))